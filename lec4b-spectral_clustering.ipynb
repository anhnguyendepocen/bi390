{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4B：谱聚类（Spectral Clustering）\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 复杂网络（complex network）\n",
    "\n",
    "复杂网络可以表示为$\\mathbf{G = (V, E)}$，其中$\\mathbf{V = \\{v_1, v_2, \\ldots, v_n\\}}$表示所有的节点的集合，$\\mathbf{E = \\{(v_i, v_j) \\lvert v_i, v_j \\in V\\}}$。复杂网络数据结构表示的时候，可用邻接矩阵或者链表的序列表示。\n",
    "\n",
    "复杂网络可以是有向图（directed graph）、无向图（undirected graph）、无权图（unweighted graph）、加权图（weighted graph）或者超图（hypergraph）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 网络聚团结构（cluster structure）\n",
    "\n",
    "也称网络社团结构（network community structure），是复杂网络中最普遍和最重要的拓扑属性（topological properties）之一。网络簇是整个网络中的稠密连接分支（densely connected subnetwork），具有同簇内部节点之间连接密集（densely），相反，不同簇节点之间连接稀疏（sparsely）的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 复杂网络分类\n",
    "\n",
    "随机网络（random network）、小世界网络（small-world network）、无标度网络（scale-free network）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 图的拉普拉斯矩阵（Laplacian matrix）\n",
    "\n",
    "也称为基尔霍夫矩阵（Kirchhoff matrix），是图的一种矩阵表示形式。\n",
    "\n",
    "> 对于一个有n个节点的图G=(V,E)，其Laplacian矩阵定义为：$\\mathbf{L = D - W}$\n",
    "\n",
    "其中，$\\mathbf{D}$为图的度矩阵，$\\mathbf{W}$为图的邻接矩阵，为了方便计算，通常我们设$\\mathbf{w_{ii}} = 0$。\n",
    "\n",
    "对于一个定点数为$n$的邻接矩阵来说，可以写成：\n",
    "$$\n",
    "\\mathbf{W} = \\left(\\begin{array}{ccc}\n",
    "w_{11} & \\cdots & w_{1n}\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "w_{n1} & \\cdots & w_{nn}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "度矩阵$\\mathbf{D}$为\n",
    "$$\n",
    "\\mathbf{D} = \\left(\n",
    "\\begin{array}{cccc}\n",
    "d_1 & 0 & \\cdots & 0\\\\\n",
    "0 & d_2 & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & d_n\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "其中$d_i = \\sum_{j=1}^n w_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Laplacian矩阵的性质\n",
    "\n",
    "- $\\mathbf{L}$是对称半正定矩阵；\n",
    "\n",
    "- $\\mathbf{L}$的最小特征值是0，其对应的特征向量是$\\mathbf{1}$；\n",
    "\n",
    "- $\\mathbf{L}$有$n$个非负实特征值$0 \\le \\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_n$，且对于任何实向量$f$，具有\n",
    "$$\n",
    "x^T L x = \\frac{1}{2}\\sum_{i,j=1}^n w_{ij}(x_i - x_j)^2\n",
    "$$\n",
    "\n",
    "__证明__:\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "x^T L x &=& x^T(D-W)x\\\\\n",
    "&=& x^T D x - x^TWx\\\\\n",
    "&=& \\sum_{i=1}^n d_i x_i^2 - \\sum_{i,j=1}^n w_{ij}x_i x_j\\\\\n",
    "&=& \\frac{1}{2}\\left(\\sum_{i=1}^n d_i x_i^2 - 2\\sum_{i,j=1}^n w_{ij}x_ix_j + \\sum_{j=1}^n d_j x_j^2 \\right)\\\\\n",
    "&=& \\frac{1}{2}\\sum_{i,j=1}^n w_{ij}(x_i - x_j)^2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "在某些情况下，拉普拉斯矩阵还可以表示为规范化的形式：\n",
    "$$\n",
    "\\mathbf{L = D^{-1/2}(D-W)D^{-1/2} = I - D^{-1/2}W D^{-1/2}}\n",
    "$$\n",
    "\n",
    "或者随机游走（random walk）的形式：\n",
    "$$\n",
    "\\mathbf{L = D^{-1}(D-A) = I - D^{-1}W}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 谱聚类（spectral clustering）\n",
    "\n",
    "在谱聚类中定义了“切割（cut）”函数的概念，当一个网络被划分成为两个子网络时，“切割”即指子网间的连接密度。谱聚类的目的就是要找到一种合理的分割，使得分割后形成若干子图（subgraph），连接不同的子图的边的权重尽可能低，即“切割”最小，相反同子图内的边的权重则尽可能要高。\n",
    "\n",
    "### 6.1 目标函数1：$\\operatorname{cut}$\n",
    "\n",
    "“切割”表示的是子网间的密度，即边比较少，且权重比较小。以二分为例，将图聚类成两个类：$S$类和$T$类。假设用$\\operatorname{cut}(S,T)$来表示图的划分，我们需要的结果是：\n",
    "$$\n",
    "\\min\\; \\operatorname{cut}(S, T) = \\sum_{i\\in S; j\\in T} e_{ij} = W(S, T)\n",
    "$$\n",
    "其中$W(S,T)$表示类别$S$与$T$之间边的权重。\n",
    "\n",
    "如果存在$k$个不同的类别$A_1, A_2, \\ldots, A_k$，则最小化的目标函数为：\n",
    "$$\n",
    "\\min\\; \\operatorname{cut}(A_1, \\ldots, A_k) = \\sum_{i=1}^k W(A_i, \\bar{A}_i)\n",
    "$$\n",
    "\n",
    "但这种“切割”函数存在一定的弊端，也就是容易出现单一的节点作为聚类的一个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 其他目标函数：$\\operatorname{RatioCut}$和$\\operatorname{NCut}$\n",
    "\n",
    "为了能够让每个类都有合理的大小，目标函数中应该使得$A_1, A_2, \\ldots, A_k$足够大，提出了$\\operatorname{RatioCut}(A_1, \\ldots, A_k)$和$\\operatorname{NCut}(A_1, \\ldots, A_k)$函数：\n",
    "\n",
    "- $\\operatorname{RatioCut}(A_1, \\ldots, A_k) = \\frac{1}{2}\\sum_{i=1}^k \\frac{W(A_i, \\bar{A}_i)}{\\lvert A_i \\rvert}$\n",
    "\n",
    "- $\\operatorname{RatioCut}(A_1, \\ldots, A_k) = \\frac{1}{2}\\sum_{i=1}^k \\frac{W(A_i, \\bar{A}_i)}{\\operatorname{vol}(A_i)}$\n",
    "\n",
    "其中$\\lvert A_i \\rvert$表示$A_i$类中包含的节点的数量，而$\\operatorname{vol}(A_i)$表示的是类$A_i$内连接总度数的大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 谱聚类的优化目标函数与拉普拉斯矩阵的关系\n",
    "\n",
    "对于二分类$k=2$的聚类问题，其优化目标函数为：\n",
    "$$\n",
    "\\min\\; \\operatorname{RatioCut}(A, \\bar{A})\n",
    "$$\n",
    "\n",
    "首先，定义向量$x = (x_1, \\ldots, x_n)^T$，且满足：\n",
    "$$\n",
    "x_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\sqrt{\\frac{\\lvert \\bar{A} \\rvert}{\\lvert A \\rvert}}, & v_i \\in A\\\\\n",
    "\\sqrt{\\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}}, & v_i \\in \\bar{A}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "已知\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "x^T L x &=& \\frac{1}{2}\\sum_{i,j=1}^n w_{ij}(x_i - x_j)^2 \\\\\n",
    "&=& \\frac{1}{2}\\sum_{i \\in A, j\\in \\bar{A}} w_{ij} \\left( \\sqrt{\\frac{\\lvert \\bar{A} \\rvert}{\\lvert A \\rvert}} + \\sqrt{\\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}}\\right)^2 + \\frac{1}{2}\\sum_{i \\in \\bar{A}, j\\in A} w_{ij} \\left( -\\sqrt{\\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}} - \\sqrt{\\frac{\\lvert \\bar{A} \\rvert}{\\lvert A \\rvert}}\\right)^2\\\\\n",
    "&=& \\frac{1}{2}\\sum_{i \\in A, j\\in \\bar{A}}w_{ij}\\left(\\frac{\\bar{\\lvert A \\rvert}}{\\lvert A \\rvert} + 2 + \\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}\\right) + \\frac{1}{2}\\sum_{i \\in \\bar{A}, j\\in A}w_{ij}\\left(\\frac{\\lvert \\bar{A} \\rvert}{\\lvert A \\rvert} + 2 + \\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}\\right)\\\\\n",
    "&=& \\frac{1}{2}\\left[\\sum_{i \\in A, j\\in \\bar{A}}w_{ij} + \\sum_{i \\in \\bar{A}, j\\in A}w_{ij} \\right]\\left( \\frac{\\bar{\\lvert A \\rvert}}{\\lvert A \\rvert} + 2 + \\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert} \\right)\\\\\n",
    "&=& \\operatorname{cut}(A, \\bar{A})\\left( \\frac{\\lvert A \\rvert + \\lvert \\bar{A} \\rvert}{\\lvert A \\vert} + \\frac{\\lvert A \\rvert + \\lvert \\bar{A} \\rvert}{\\lvert \\bar{A} \\rvert}\\right)\\\\\n",
    "&=& (\\lvert A \\rvert + \\lvert \\bar{A} \\rvert) \\operatorname{RatioCut}(A, \\bar{A})\\\\\n",
    "&=& \\lvert V \\rvert \\cdot \\operatorname{RatioCut}(A, \\bar{A})\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "这样我们就在拉普拉斯矩阵和最优化图聚类函数之间建立了联系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于$\\lvert V \\rvert$是常数，因此$\\min\\; \\operatorname{RatioCut}(A, \\bar{A})$也就相当于：\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\min & x^T L x\\\\\n",
    "\\textit{s.t.} & x \\perp \\mathbf{1}, \\lVert x \\rVert = \\sqrt{n}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "同时还有：\n",
    "$$\n",
    "x_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\sqrt{\\frac{\\lvert \\bar{A} \\rvert}{\\lvert A \\rvert}}, & v_i \\in A\\\\\n",
    "\\sqrt{\\frac{\\lvert A \\rvert}{\\lvert \\bar{A} \\rvert}}, & v_i \\in \\bar{A}\\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设$\\lambda$是拉普拉斯矩阵$L$的特征值，对应的特征向量为$x$，则有\n",
    "$$\n",
    "L x = \\lambda x\n",
    "$$\n",
    "左右两端同时乘以$x^T$，得到\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "x^T L x &=& x^T \\lambda x\\\\\n",
    "&=& \\lambda n\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "因此要$\\min\\; x^T L x$，也就是要求$L$的最小特征值。我们已知$L$的最小特征值为0，由Rayleigh-Ritz定理，需要求$L$的次小特征值以及对应的特征向量$x$，最后根据$x$的符号对对应的节点进行聚类：\n",
    "$$\n",
    "v_i \\in \\left\\{\n",
    "\\begin{array}{ll}\n",
    "A, & x_i \\ge 0\\\\\n",
    "\\bar{A}, & x_i < 0\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\S$为什么称为谱聚类？\n",
    "\n",
    "对于方阵（square matrix）这种线性算子来说，其所有特征值（eigenalues）被统称为**方阵的谱（spectrum）**，其最大的特征值被称为方阵的**谱半径（spectral radius）**。对于普通矩阵（非方阵）$A$来说，其特征谱则为**$A^TA$的所有特征值**。\n",
    "\n",
    "谱聚类方法本质上是一种基于图论的聚类算法，通过对样本数据的拉普拉斯矩阵的**部分特征向量（本质上是一种降维）**进行聚类，从而达到对样本数据进行聚类的目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 从二分类问题到$k$分类问题\n",
    "\n",
    "取**拉普拉斯矩阵$L$的最小的$k$个特征值对应的$k$个特征向量$x^{(1)}, x^{(2)}, \\ldots, x^{(k)}$构建对应的特征矩阵**：\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{cccc}\n",
    "x_1^{(1)} & x_1^{(2)} & \\cdots & x_1^{(k)}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "x_n^{(1)} & x_n^{(2)} & \\cdots & x_n^{(k)}\n",
    "\\end{array}\n",
    "\\right)_{n \\times k}\n",
    "$$\n",
    "\n",
    "将每行作为一个样本，再采用$k$-means进行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 小结\n",
    "\n",
    "综上所述，谱聚类的一般过程是：\n",
    "\n",
    "<ol type=1>\n",
    "    <li>对于给定的图$G=(V,E)$，求图的度矩阵$D$和邻接矩阵$A$，计算图的Laplacian矩阵$L=D-A$；</li>\n",
    "    <li>对Laplacian矩阵进行特征分解，取其前个特征值对应的特征向量，构成$n \\times k$的特征向量矩阵；</li>\n",
    "    <li>利用$k$-Means聚类算法对上述的的特征向量矩阵进行聚类，每一行代表一个样本点。</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 谱聚类的拓展\n",
    "\n",
    "我们还可以通过相似性矩阵构造拉普拉斯矩阵，也就是相似性矩阵\n",
    "$$\n",
    "S = \\left(\n",
    "\\begin{array}{cccc}\n",
    "s_{11} & s_{12} & \\cdots & s_{1n}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "s_{n1} & s_{n2} & \\cdots & s_{nn}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "其中\n",
    "$$\n",
    "s_{ij} = \\exp\\left(-\\frac{w_{ij}^2}{\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "再利用相似性矩阵$S$构造拉普拉斯矩阵$L = D - S$，其中$D$是相似度矩阵计算得到的度矩阵。\n",
    "\n",
    "#### 【注意】\n",
    "\n",
    "- 使用距离矩阵得到的拉普拉斯矩阵进行谱聚类的时候，必须计算$L$的$k$个最大特征值对应的特征向量，而非最小的$k$个特征值。\n",
    "\n",
    "- 如果用相似度矩阵得到的拉普拉斯矩阵进行谱聚类，必须计算计算$L$的$k$个最小特征值对应的特征向量。\n",
    "\n",
    "我们更倾向于使用相似矩阵进行计算。对于距离矩阵，我们总喜欢将其转化为相似矩阵后再执行谱聚类算法。\n",
    "\n",
    "#### 如何确定谱聚类的$k$值\n",
    "\n",
    "一种情况下，$k$值是先验的。否则我们可以通过公式$k^* = \\operatorname{argmax_k}\\,\\lvert \\lambda_{k+1} - \\lambda_k \\rvert$得到$k$值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import scipy.io as scio\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg.eigen import arpack\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specClust(data, sigma, k):\n",
    "    data = sparse.csc_matrix.multiply(data, data)\n",
    "    data = -data/(2*sigma**2)\n",
    "    S = sparse.csc_matrix.expm1(data) + \\\n",
    "        sparse.csc_matrix.multiply(sparse.csc_matrix.sign(data), sparse.csc_matrix.sign(data))\n",
    "    D = S.sum(axis=1)\n",
    "    D = sqrt(1/D)\n",
    "    n = len(D)\n",
    "    D = D.T\n",
    "    D = sparse.spdiags(D, 0, n, n)\n",
    "    L = D * S * D\n",
    "    \n",
    "    vals, vecs = arpack.eigs(L, k=k, tol=0, which=\"LM\")\n",
    "    sq_sum = sqrt(multiply(vecs,vecs).sum(axis=1))\n",
    "    m1, m2 = shape(vecs)\n",
    "    \n",
    "    for i in xrange(m1):\n",
    "        for j in xrange(m2):\n",
    "            vecs[i,j] = vecs[i,j] / sq_sum[i]\n",
    "            \n",
    "    myCentroids, clustAssing = kMeans(vecs, num_clusters)\n",
    "    \n",
    "    for i in xrange(shape(clustAssing)[0]):\n",
    "        print clustAssing[i,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randCent(data, k):\n",
    "    n = shape(data)[1]\n",
    "    centroids = matrix(zeros((k, n)))\n",
    "    for j in range(n):\n",
    "        minJ = min(data[:,j])\n",
    "        rangeJ = float(max(data[:,j]), minJ)\n",
    "        centroids[:,j] = mat(minJ + rangeJ * random.rand(k, 1))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distEuclidean(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2)))\n",
    "    centroids = randCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):\n",
    "            minDist = inf; minIndex = ''\n",
    "            for j in range(k):\n",
    "                distJI = distEclud(centroids[j,:],dataSet[i,:])\n",
    "                if distJI > minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex:\n",
    "                clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex, minDist**2\n",
    "        \n",
    "        for cent in range(k):\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0].A==cent)[0]]\n",
    "            centroids[cent,:] = mean(ptsInClust, axis=0)\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录1：未正则化的拉普拉斯矩阵的谱聚类算法\n",
    "\n",
    "1. 输入$n$个数据$\\{x_i\\}, i=1,\\ldots,n$\n",
    "\n",
    "2. 计算$n \\times n$的相似度矩阵$\\mathbf{W}$和度矩阵$\\mathbf{D}$\n",
    "\n",
    "3. 计算拉普拉斯矩阵$\\mathbf{L = D - W}$\n",
    "\n",
    "4. 计算$\\mathbf{L}$的最小$k$个特征值对应的$k$个特征向量$\\mathbf{u_1, \\ldots, u_k}$\n",
    "\n",
    "5. 将$k$个特征向量组成矩阵$\\mathbf{U} \\in \\mathbb{R}^{n \\times k}$\n",
    "\n",
    "6. 执行$k$-means聚类对$\\mathbf{U}$进行行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录2：对称正则化的拉普拉斯矩阵的谱聚类算法\n",
    "\n",
    "1. 输入$n$个数据$\\{x_i\\}, i=1,\\ldots,n$\n",
    "\n",
    "2. 计算$n \\times n$的相似度矩阵$\\mathbf{W}$和度矩阵$\\mathbf{D}$\n",
    "\n",
    "3. 计算拉普拉斯矩阵$\\mathbf{L = D^{-1/2}(D - W)D^{-1/2}}$\n",
    "\n",
    "4. 计算$\\mathbf{L}$的最小$k$个特征值对应的$k$个特征向量$\\mathbf{u_1, \\ldots, u_k}$\n",
    "\n",
    "5. 将$k$个特征向量组成矩阵$\\mathbf{U} \\in \\mathbb{R}^{n \\times k}$\n",
    "\n",
    "6. 对$\\mathbf{U}$的每行进行单位化处理，将其结果存为$\\mathbf{Y}$，也就是$\\lVert \\mathbf{y_i} \\rVert = 1$\n",
    "\n",
    "6. 执行$k$-means聚类对$\\mathbf{Y}$进行行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录3：随机游走的拉普拉斯矩阵的谱聚类算法\n",
    "\n",
    "1. 输入$n$个数据$\\{x_i\\}, i=1,\\ldots,n$\n",
    "\n",
    "2. 计算$n \\times n$的相似度矩阵$\\mathbf{W}$和度矩阵$\\mathbf{D}$\n",
    "\n",
    "3. 计算拉普拉斯矩阵$\\mathbf{L = D^{-1}(D - W)}$\n",
    "\n",
    "4. 计算$\\mathbf{L}$的最小$k$个特征值对应的$k$个特征向量$\\mathbf{u_1, \\ldots, u_k}$\n",
    "\n",
    "5. 将$k$个特征向量组成矩阵$\\mathbf{U} \\in \\mathbb{R}^{n \\times k}$\n",
    "\n",
    "6. 执行$k$-means聚类对$\\mathbf{U}$进行行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 附录4： 随机游走与拉普拉斯矩阵的关系\n",
    "\n",
    "图论中的随机游走是一个随机过程，它从一个节点跳转到另外一个节点。谱聚类即试图找到图的一个划分，使得随机游走在相同的簇中停留而几乎不会游走到其他簇。\n",
    "\n",
    "#### 随机游走的转移矩阵\n",
    "\n",
    "从节点$v_i$跳转到节点$v_j$的概率正比于边的权值$w_{ij}$：\n",
    "$$\n",
    "p_{ij} = \\frac{w_{ij}}{d_i}\n",
    "$$\n",
    "这里的$\\{p_{ij}\\}$构成的矩阵就是拉普拉斯矩阵：\n",
    "$$\n",
    "P = D^{-1} W = L_{rw}\n",
    "$$\n",
    "\n",
    "对于随机游走算法，可参考文献：\n",
    "\n",
    "[Fast Random Walk with Restart and Its Applications](http://repository.cmu.edu/cgi/viewcontent.cgi?article=1533&context=compsci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录5：谱聚类的应用\n",
    "\n",
    "请参见文章[Spectral clustering of microarray data elucidates the roles of microenvironment remodeling and immune responses in survival of head and neck squamous cell carcinoma.](http://www.ncbi.nlm.nih.gov/pubmed/20458058)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
