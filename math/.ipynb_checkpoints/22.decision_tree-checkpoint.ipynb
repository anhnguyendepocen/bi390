{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二十二讲：决策树（Decision tree）\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 信息论\n",
    "在介绍决策树之前，我们必须来看看几个信息论中的几个重要概念：信息熵（information entropy）、联合熵（joint entropy）、相对熵（relative entropy）、信息增益（information gain）等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 决策树的概念\n",
    "本质上决策树是一种递归的、贪婪的持续降低系统的信息熵的过程。\n",
    "Decision tree is intrinsically a recursive and greedy approach to reducing the information entropy (uncertainty) of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 决策树算法的关键\n",
    "ID3 (信息增益information gain) $\\Rightarrow$ C4.5 (信息增益率Information gain rate) $\\Rightarrow$ CART (基尼系数Gini index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 决策树的后处理（Post-processing）\n",
    "\n",
    "为了避免过拟合，必须对决策树进行约束或处理，其中一种方法就是后剪枝（post-pruning）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 随机森林（Random forests）\n",
    "\n",
    "随机森林是一种ensemble的策略，避免决策树过拟合的重要方法，其基本的手段就是通过bootstraping。Bootstrapping的名称来源于一个俚语 - Pull up your own bootstraps，其意义是完全依靠自身的资源，中文翻译为“自助法”，其本质是一种有放回的抽样方法（resampling with replacement）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
